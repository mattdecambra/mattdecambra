---
title: "Geography 176A"
author: "[Matt DeCambra](https://mattdecambra.github.io)"
subtitle: 'Lab 04:'
output:
  html_document:
    theme: journal
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, out.width = "75%", fig.align = 'center')

library(tidyverse)
library(sf)
library(units)
library(leaflet)
library(spatstat)

library(USAboundaries)
library(rnaturalearth)
library(gghighlight)

library(ggrepel)
library(knitr)
```
```{r}
CONUS= USAboundaries::us_counties(resolution = "low") %>%
  filter(!(state_name %in% c( 'Puerto Rico', 'Alaska', 'Hawaii')))
conusbound= USAboundaries::us_boundaries(resolution = "low") %>%
  filter(!(state_name %in% c( 'Puerto Rico', 'Alaska', 'Hawaii')))
conusbound <- st_transform(conusbound, 5070)

regions = data.frame(region = state.region, state_name = state.name)
uscounty = left_join(us_counties(), regions) %>% 
  filter(!(state_name %in% c( 'Puerto Rico', 'Alaska', 'Hawaii'))) %>% 
  st_transform(st_crs(5070))

state_county = uscounty %>% 
  group_by(state_name) %>% summarise()
uscentroid = st_centroid(uscounty) %>% 
  st_union() %>% 
  st_cast("MULTIPOINT")
plot(state_county$geometry)


CONUS <- st_transform(CONUS,5070)

conus_cent = st_centroid(CONUS) %>% 
  st_union %>% 
  st_cast("MULTIPOINT")
#Creating Plot function
plot_tess = function(data, title){
  ggplot() + 
    geom_sf(data = data, fill = "white", col = "navy", size = .2) +   
    theme_void() +
    labs(title = title, caption = paste("This tesselation has:", nrow(data), "tiles" )) +
    theme(plot.title = element_text(hjust = .5, color =  "navy", face = "bold"))
}
#Creating 4 different surfaces 1.3
veroni = st_voronoi(conus_cent) %>% 
  st_cast() %>% 
  st_as_sf() %>% 
  mutate(id = 1:n())

triang = st_triangulate(conus_cent) %>% 
  st_cast() %>% 
  st_as_sf() %>% 
  mutate(id = 1:n())


sq_grid = st_make_grid(CONUS, n = c(70, 50)) %>% 
  st_as_sf() %>% 
  mutate(id = 1:n())

sq_hex = st_make_grid(CONUS, n = c(70, 50), square = FALSE) %>% 
  st_as_sf() %>% 
  mutate(id = 1:n())



simp_conus = rmapshaper::ms_simplify(conusbound, keep = .05)
 
mapview::npts(conusbound)
mapview::npts(simp_conus)
#Original was equal to 11193 point and the simplified was 818. I was able to remove 10375 points. 

triang = st_intersection(triang, st_union(simp_conus))


veroni = st_intersection(veroni, st_union(simp_conus))

#Final plots 1.7
plot_tess(triang, "Triangle")
plot_tess(veroni, "Voroni")
plot_tess(sq_grid, " Square Grid")
plot_tess(sq_hex, "Hexagonal Grid")
```

```{r}
#Question 2.1
get_df = function(data,title){
  areas = st_area(data)
         areas = units::set_units(areas, "km2")
         areas = units::drop_units(areas)
         data.frame(mean = mean(areas), sd = sd(areas), area = areas, text = title, count = sum(areas))
         
}


#Question 2.2
get_df(triang, "test")  
get_df(veroni, "test") 
get_df(sq_grid, "Square") 
get_df(sq_hex, "Hexagonal") 
get_df(CONUS, "OG Counties")

tess_summary = bind_rows(
  get_df(triang, "Trianguation"), # Seem to have very large standard deviation values
  get_df(veroni, "Voroni"), #Due to 
  get_df(sq_grid, "Square"), #All areas are equal, might make it more difficult for mean analysis.
  get_df(sq_hex, "Hexagonal"), # Standard deviation of 0, all areas equal but slightly smaller then square
  get_df(CONUS, "OG Counties")
)
#2.5
  knitr::kable(tess_summary, 
             caption = "Five tessellation summaries",
             col.names = c("Mean", "Standard Deviation", "Area", "Type", "Count"),
             max.rows = 6,
             format.args = list(big.mark = ",")) 
```

```{r}
library(readxl)

dams = read_excel("../data/NID2019_U.xlsx") %>% 
  filter(!is.na(LATITUDE))

damns = dams %>% 
  filter(!is.na("LATITUDE")) %>% 
  st_as_sf(coords = c("LONGITUDE", "LATITUDE"), crs = 4326) %>% 
  st_transform(5070)


point_in_poly = function(points, polygon,ID){
  st_join(polygon, points) %>% 
    count(geoid)
}

#3.2
tryfuntion = function(points, polygon, group){
  st_join(polygon, points) %>% 
    st_drop_geometry() %>% 
    count(get(group)) %>% 
    setNames(c(group, "n")) %>%
    left_join(polygon, by = group) %>% 
    st_as_sf() 
}


#3.4
plot_pip = function(data){
  ggplot() + 
    geom_sf(data = data, aes(fill = log(n)), alpha = .9, size = .2) + 
    scale_fill_gradient(low = "white", high = "darkblue") + 
    theme_void() + 
    theme(legend.position = 'none',
          plot.title = element_text(face = "bold", color = "darkblue", hjust = .5, size = 24)) +
    labs(title = "Dams in the US",
         caption = paste0(sum(data$n), " locations represented")) 
}

#3.5

veroni_pip = tryfuntion(points = damns, polygon = veroni, group = "id")

plot_pip(veroni_pip)

triang_pip = tryfuntion(points = damns, polygon = triang, group = "id")

plot_pip(triang_pip)

square_pip = tryfuntion(points = damns, polygon = sq_grid, group = "id")

plot_pip(square_pip)

hex_pip = tryfuntion(points = damns, polygon = sq_hex, group = "id")

plot_pip(hex_pip)
plot_pip(square_pip)
plot_pip(triang_pip)
plot_pip(veroni_pip)
#Each tessellation is going to display the visualization of dams differently and will attribute to MAUP problem.Even thought the square one is even,
# I believe that the voroni tessellation will better represent the dams data.

```
damns %>% 
  filter(grepl("R", PURPOSES)) %>% 
  tryfuntion(veroni, "id") %>% 
  plot_pip() + 
  gghighlight::gghighlight(n >= (mean(n) + sd(n)))

damns %>% 
  filter(grepl("C",PURPOSES)) %>% 
  tryfuntion(veroni, "id") %>% 
  plot_pip() +
  gghighlight::gghighlight(n >= (mean(n) + sd(n)))

damns %>% 
  filter(grepl("P", PURPOSES)) %>%
  tryfuntion(veroni, "id") %>% 
  plot_pip() +
  gghighlight::gghighlight(n >= (mean(n) + sd(n)))

damns %>% 
  filter(grepl("H", PURPOSES)) %>%
  tryfuntion(veroni, "id") %>% 
  plot_pip() +
  gghighlight::gghighlight(n >= (mean(n) + sd(n)))
```{r}

 


